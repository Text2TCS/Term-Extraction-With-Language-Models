{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Term Extraction Token Classifier",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsd6QWA0JUgbYmp2ibk1Hf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c019229186e4a99b51ab9bbe4c5b784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_345ae3166eff49338827b7a5c7d93d05",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91d1ab635bc94af5abe773e177d09461",
              "IPY_MODEL_184b49ae656d47e6bfecc7cb3f508dd8"
            ]
          }
        },
        "345ae3166eff49338827b7a5c7d93d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91d1ab635bc94af5abe773e177d09461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd23992f5063466cbe78e07f5318663a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fda1de93c9b64edaa54e83dae313ab9a"
          }
        },
        "184b49ae656d47e6bfecc7cb3f508dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_10e7746c509342e9881fb2d7644d71c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:02&lt;00:00, 1.72MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfae5588591b4cd0993d3324ad5d1c8d"
          }
        },
        "bd23992f5063466cbe78e07f5318663a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fda1de93c9b64edaa54e83dae313ab9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10e7746c509342e9881fb2d7644d71c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfae5588591b4cd0993d3324ad5d1c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fb35ed19a634443810db6013a595bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80536fcb301343ad8c43a05a68c58120",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a73b08b27a5740eb9320a4a467446088",
              "IPY_MODEL_7554d113a0f54da3b649252fd8969df3"
            ]
          }
        },
        "80536fcb301343ad8c43a05a68c58120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a73b08b27a5740eb9320a4a467446088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_895b16272a4f4c32a1f572d73eaec700",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_947011ec13c7404390295e9e2ee39caf"
          }
        },
        "7554d113a0f54da3b649252fd8969df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83db5fd4d6db4caa885164519ef833cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9.10M/9.10M [00:01&lt;00:00, 7.29MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43b31066b58a40f18fd97596b38aef76"
          }
        },
        "895b16272a4f4c32a1f572d73eaec700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "947011ec13c7404390295e9e2ee39caf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83db5fd4d6db4caa885164519ef833cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43b31066b58a40f18fd97596b38aef76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lwachowiak/Term-Extraction-With-Language-Models/blob/main/Term_Extraction_Token_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yMTmZptEkHC"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaxWLY9GFE2W"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sacremoses\n",
        "!pip install sentencepiece\n",
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9fYtB3_FHuK"
      },
      "source": [
        "#torch and tranformers for model and training\n",
        "import torch  \n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset\n",
        "from transformers import XLMRobertaTokenizerFast              \n",
        "from transformers import XLMRobertaForTokenClassification\n",
        "from transformers import AdamW                            \n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import sentencepiece\n",
        "\n",
        "#sklearn for evaluation\n",
        "from sklearn import preprocessing                       \n",
        "from sklearn.metrics import classification_report        \n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import ParameterGrid         \n",
        "from sklearn.model_selection import ParameterSampler      \n",
        "from sklearn.utils.fixes import loguniform\n",
        "\n",
        "#nlp preprocessing\n",
        "from nltk import ngrams                                 \n",
        "from spacy.pipeline import SentenceSegmenter\n",
        "from spacy.lang.en import English\n",
        "from spacy.pipeline import Sentencizer\n",
        "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
        "\n",
        "\n",
        "#utilities\n",
        "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "import glob, os\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "import pickle         # for saving data structures\n",
        "from pynvml import *  # for checking gpu memory"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyekDMZ28gBc",
        "outputId": "ff6b00cb-4b3c-4a4f-ec85-e00296791586"
      },
      "source": [
        "# connect to GPU \n",
        "device = torch.device('cuda')\n",
        "\n",
        "print('Connected to GPU:', torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connected to GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RPZ14sYHHUm"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKqV3YfXHSNz"
      },
      "source": [
        "Training Data: corp, wind\n",
        "\n",
        "Validation Data: equi\n",
        "\n",
        "Test Data: htfl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERUBsPPOFfe1"
      },
      "source": [
        "#load terms\n",
        "\n",
        "#en\n",
        "df_corp_terms_en=pd.read_csv('ACTER-master/ACTER-master/en/corp/annotations/corp_en_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "df_equi_terms_en=pd.read_csv('ACTER-master/ACTER-master/en/equi/annotations/equi_en_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "df_htfl_terms_en=pd.read_csv('ACTER-master/ACTER-master/en/htfl/annotations/htfl_en_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "df_wind_terms_en=pd.read_csv('ACTER-master/ACTER-master/en/wind/annotations/wind_en_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "\n",
        "#fr\n",
        "df_corp_terms_fr=pd.read_csv('ACTER-master/ACTER-master/fr/corp/annotations/corp_fr_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "df_equi_terms_fr=pd.read_csv('ACTER-master/ACTER-master/fr/equi/annotations/equi_fr_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "df_htfl_terms_fr=pd.read_csv('ACTER-master/ACTER-master/fr/htfl/annotations/htfl_fr_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "df_wind_terms_fr=pd.read_csv('ACTER-master/ACTER-master/fr/wind/annotations/wind_fr_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "\n",
        "#nl\n",
        "df_corp_terms_nl=pd.read_csv('ACTER-master/ACTER-master/nl/corp/annotations/corp_nl_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "df_equi_terms_nl=pd.read_csv('ACTER-master/ACTER-master/nl/equi/annotations/equi_nl_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "df_htfl_terms_nl=pd.read_csv('ACTER-master/ACTER-master/nl/htfl/annotations/htfl_nl_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "df_wind_terms_nl=pd.read_csv('ACTER-master/ACTER-master/nl/wind/annotations/wind_nl_terms_nes.ann', delimiter=\"\\t\", names=[\"Term\", \"Label\"])  \n",
        "\n",
        "labels=[\"Random\", \"Term\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tw11QcsHF8Gc",
        "outputId": "18b520b6-2e7f-43e3-8b14-5ea4de9e6edf"
      },
      "source": [
        "# show dataframe\n",
        "df_wind_terms_en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>48/600</td>\n",
              "      <td>Named_Entity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4energia</td>\n",
              "      <td>Named_Entity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4energy</td>\n",
              "      <td>Named_Entity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ab \"lietuvos energija\"</td>\n",
              "      <td>Named_Entity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ab lietuvos elektrine</td>\n",
              "      <td>Named_Entity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1529</th>\n",
              "      <td>zhiquan</td>\n",
              "      <td>Named_Entity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1530</th>\n",
              "      <td>çetinkaya</td>\n",
              "      <td>Named_Entity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1531</th>\n",
              "      <td>çeti̇nkaya</td>\n",
              "      <td>Named_Entity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1532</th>\n",
              "      <td>çeşme</td>\n",
              "      <td>Named_Entity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1533</th>\n",
              "      <td>özgen</td>\n",
              "      <td>Named_Entity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1534 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Term         Label\n",
              "0                     48/600  Named_Entity\n",
              "1                   4energia  Named_Entity\n",
              "2                    4energy  Named_Entity\n",
              "3     ab \"lietuvos energija\"  Named_Entity\n",
              "4      ab lietuvos elektrine  Named_Entity\n",
              "...                      ...           ...\n",
              "1529                 zhiquan  Named_Entity\n",
              "1530               çetinkaya  Named_Entity\n",
              "1531              çeti̇nkaya  Named_Entity\n",
              "1532                   çeşme  Named_Entity\n",
              "1533                   özgen  Named_Entity\n",
              "\n",
              "[1534 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU7NMPaDvbWt"
      },
      "source": [
        "**Functions for preprocessing and creating of Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_stqlIDvZxA"
      },
      "source": [
        "#load all text files from folder into a string\n",
        "def load_text_corpus(path):\n",
        "  text_data=\"\"\n",
        "  print(glob.glob(path))\n",
        "  for file in glob.glob(path+\"*.txt\"):\n",
        "      print(file)\n",
        "      with open(file) as f:\n",
        "        temp_data = f.read()\n",
        "        print(len(temp_data))\n",
        "        text_data=text_data+\" \"+temp_data\n",
        "  print(len(text_data))\n",
        "  return text_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nXtHwAyPoK0"
      },
      "source": [
        "#split in sentences and tokenize\n",
        "def preprocess(text):\n",
        "  #sentenize (from spacy)\n",
        "  sentencizer = Sentencizer()\n",
        "  nlp = English()\n",
        "  nlp.add_pipe(sentencizer)\n",
        "  doc = nlp(text)\n",
        "\n",
        "  #tokenize\n",
        "  sentence_list=[]\n",
        "  mt = MosesTokenizer(lang='en')\n",
        "  for s in doc.sents:\n",
        "    tokenized_text = mt.tokenize(s, return_str=True)    #append tuple of tokens and original senteence\n",
        "  return sentence_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPUGg3GD9d5W"
      },
      "source": [
        "#find indices of a sublist sub in a list l\n",
        "def find_sub_list(subl,l):\n",
        "    results=[]\n",
        "    subllen=len(subl)\n",
        "    for ind in (i for i,e in enumerate(l) if e==subl[0]):\n",
        "        if l[ind:ind+subllen]==subl:\n",
        "            results.append((ind,ind+subllen-1))\n",
        "\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qBA_KhoQkhB"
      },
      "source": [
        "#input is list of sentences and dataframe containing terms\n",
        "def create_training_data(sentence_list, df_terms, n):\n",
        "\n",
        "  #create empty dataframe\n",
        "  training_data = []\n",
        "\n",
        "  md = MosesDetokenizer(lang='en')\n",
        "\n",
        "  print(len(sentence_list))\n",
        "  count=0\n",
        "\n",
        "  for sen in sentence_list:\n",
        "    count+=1\n",
        "    if count%100==0:print(count)\n",
        "\n",
        "    s=sen[0]  #take first part of tuple, i.e. the tokens\n",
        "\n",
        "    #create label list, with \"n\" for non-terms, \"B-T\" for beginning of a term and \"T\" for the continuation of a term\n",
        "    tags=[\"n\"]*len(s)\n",
        "\n",
        "    # 1-gram up to n-gram\n",
        "    for i in range(1,n+1):\n",
        "      #create n-grams of this sentence\n",
        "      n_grams = ngrams(s, i)\n",
        "\n",
        "      #look if n-grams are in the annotation dataset\n",
        "      for n_gram in n_grams: \n",
        "        n_gram_aslist=list(n_gram)\n",
        "        n_gram=md.detokenize(n_gram) \n",
        "        context=str(sen[1]).strip()\n",
        "        #if yes add an entry to the training data\n",
        "        if n_gram.lower() in df_terms.values:\n",
        "          #check where n_gram is in sentence and annotate it \n",
        "          #print(n_gram_aslist,s)\n",
        "          sublist_indices=find_sub_list(n_gram_aslist, s)\n",
        "          for indices in sublist_indices:\n",
        "            for ind in range(indices[0],indices[1]+1):\n",
        "              #if term start\n",
        "              if ind==indices[0]:\n",
        "                tags[ind]=\"B-T\"\n",
        "              #if continuation of a Term\n",
        "              else: \n",
        "                tags[ind]=\"T\"\n",
        "\n",
        "    training_data.append((s,tags))\n",
        "        \n",
        "\n",
        "  return training_data\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HhBTwYl1-dy"
      },
      "source": [
        "**Create Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UemCf-2xPrn1"
      },
      "source": [
        "#create trainings data for all corp texts\n",
        "corp_text_en=load_text_corpus(\"ACTER-master/ACTER-master/en/corp/texts/annotated/\") # load text\n",
        "corp_s_list=preprocess(corp_text_en)                                                # preprocess\n",
        "train_data_corp_en=create_training_data(corp_s_list, df_corp_terms_en, 6)           # create training data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzCWke974lJS"
      },
      "source": [
        "#create trainings data for all wind texts\n",
        "wind_text_en=load_text_corpus(\"ACTER-master/ACTER-master/en/wind/texts/annotated/\") # load text\n",
        "wind_s_list=preprocess(wind_text_en)                                                # preprocess\n",
        "train_data_wind_en=create_training_data(wind_s_list, df_wind_terms_en, 6)           # create training data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGeV2rgS4lbn"
      },
      "source": [
        "#create trainings data for all equi texts\n",
        "equi_text_en=load_text_corpus(\"ACTER-master/ACTER-master/en/equi/texts/annotated/\") # load text\n",
        "equi_s_list=preprocess(equi_text_en)                                                # preprocess\n",
        "train_data_equi_en=create_training_data(equi_s_list, df_equi_terms_en, 6)           # create training data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCsU8wUE4lmk"
      },
      "source": [
        "#create trainings data for all htfl texts\n",
        "htfl_text_en=load_text_corpus(\"ACTER-master/ACTER-master/en/htfl/texts/annotated/\") # load text\n",
        "htfl_s_list=preprocess(htfl_text_en)                                                # preprocess\n",
        "train_data_htfl_en=create_training_data(htfl_s_list, df_htfl_terms_en, 6)           # create training data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSju0fa5m5Vj"
      },
      "source": [
        "#fr\n",
        "corp_text_fr=load_text_corpus(\"ACTER-master/ACTER-master/fr/corp/texts/annotated/\") # load text\n",
        "corp_s_list=preprocess(corp_text_fr)                                                # preprocess\n",
        "train_data_corp_fr=create_training_data(corp_s_list, df_corp_terms_fr, 6)           # create training data\n",
        "\n",
        "wind_text_fr=load_text_corpus(\"ACTER-master/ACTER-master/fr/wind/texts/annotated/\") # load text\n",
        "wind_s_list=preprocess(wind_text_fr)                                                # preprocess\n",
        "train_data_wind_fr=create_training_data(wind_s_list, df_wind_terms_fr, 6)           # create training data\n",
        "\n",
        "equi_text_fr=load_text_corpus(\"ACTER-master/ACTER-master/fr/equi/texts/annotated/\") # load text\n",
        "equi_s_list=preprocess(equi_text_fr)                                                # preprocess\n",
        "train_data_equi_fr=create_training_data(equi_s_list, df_equi_terms_fr, 6)           # create training data\n",
        "\n",
        "htfl_text_fr=load_text_corpus(\"ACTER-master/ACTER-master/fr/htfl/texts/annotated/\") # load text\n",
        "htfl_s_list=preprocess(htfl_text_fr)                                                # preprocess\n",
        "train_data_htfl_fr=create_training_data(htfl_s_list, df_htfl_terms_fr, 6)           # create training data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQt-Z0p2m5Zy"
      },
      "source": [
        "#nl\n",
        "corp_text_nl=load_text_corpus(\"ACTER-master/ACTER-master/nl/corp/texts/annotated/\") # load text\n",
        "corp_s_list=preprocess(corp_text_nl)                                                # preprocess\n",
        "train_data_corp_nl=create_training_data(corp_s_list, df_corp_terms_nl, 6)           # create training data\n",
        "\n",
        "wind_text_nl=load_text_corpus(\"ACTER-master/ACTER-master/nl/wind/texts/annotated/\") # load text\n",
        "wind_s_list=preprocess(wind_text_nl)                                                # preprocess\n",
        "train_data_wind_nl=create_training_data(wind_s_list, df_wind_terms_nl, 6)           # create training data\n",
        "\n",
        "equi_text_nl=load_text_corpus(\"ACTER-master/ACTER-master/nl/equi/texts/annotated/\") # load text\n",
        "equi_s_list=preprocess(equi_text_nl)                                                # preprocess\n",
        "train_data_equi_nl=create_training_data(equi_s_list, df_equi_terms_nl, 6)           # create training data\n",
        "\n",
        "htfl_text_nl=load_text_corpus(\"ACTER-master/ACTER-master/nl/htfl/texts/annotated/\") # load text\n",
        "htfl_s_list=preprocess(htfl_text_nl)                                                # preprocess\n",
        "train_data_htfl_nl=create_training_data(htfl_s_list, df_htfl_terms_nl, 6)           # create training data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSy8hZggPQpf",
        "outputId": "ee451206-219a-4318-d90c-898d39c15bec"
      },
      "source": [
        "#concat trainingsdata\n",
        "trainings_data = train_data_corp_en + train_data_wind_en\n",
        "\n",
        "val_data = train_data_equi_en + train_data_equi_fr + train_data_equi_nl\n",
        "val_data_en = train_data_equi_en\n",
        "val_data_fr = train_data_equi_fr\n",
        "val_data_nl = train_data_equi_nl\n",
        "\n",
        "test_data = train_data_htfl_en + train_data_htfl_fr + train_data_htfl_nl\n",
        "test_data_en = train_data_htfl_en\n",
        "test_data_fr = train_data_htfl_fr\n",
        "test_data_nl = train_data_htfl_nl\n",
        "\n",
        "gold_set_for_validation=set(df_equi_terms_en[\"Term\"]).union(set(df_equi_terms_fr[\"Term\"])).union(set(df_equi_terms_nl[\"Term\"])) \n",
        "\n",
        "print(len(trainings_data))\n",
        "print(len(val_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3449\n",
            "7978\n",
            "6416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdoXY46fSoxS"
      },
      "source": [
        "#seperate tokens and tags\n",
        "\n",
        "#train\n",
        "train_tags=[tup[1] for tup in trainings_data]\n",
        "train_texts=[tup[0] for tup in trainings_data]\n",
        "\n",
        "#val\n",
        "val_tags=[tup[1] for tup in val_data]\n",
        "val_texts=[tup[0] for tup in val_data]\n",
        "\n",
        "val_tags_en=[tup[1] for tup in val_data_en]\n",
        "val_texts_en=[tup[0] for tup in val_data_en]\n",
        "\n",
        "val_tags_fr=[tup[1] for tup in val_data_fr]\n",
        "val_texts_fr=[tup[0] for tup in val_data_fr]\n",
        "\n",
        "val_tags_nl=[tup[1] for tup in val_data_nl]\n",
        "val_texts_nl=[tup[0] for tup in val_data_nl]\n",
        "\n",
        "#test\n",
        "test_tags=[tup[1] for tup in test_data]\n",
        "test_texts=[tup[0] for tup in test_data]\n",
        "\n",
        "test_tags_en=[tup[1] for tup in test_data_en]\n",
        "test_texts_en=[tup[0] for tup in test_data_en]\n",
        "\n",
        "test_tags_fr=[tup[1] for tup in test_data_fr]\n",
        "test_texts_fr=[tup[0] for tup in test_data_fr]\n",
        "\n",
        "test_tags_nl=[tup[1] for tup in test_data_nl]\n",
        "test_texts_nl=[tup[0] for tup in test_data_nl]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVxAsANXfpDv"
      },
      "source": [
        "# Tokenize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ieMHql0gobX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "2c019229186e4a99b51ab9bbe4c5b784",
            "345ae3166eff49338827b7a5c7d93d05",
            "91d1ab635bc94af5abe773e177d09461",
            "184b49ae656d47e6bfecc7cb3f508dd8",
            "bd23992f5063466cbe78e07f5318663a",
            "fda1de93c9b64edaa54e83dae313ab9a",
            "10e7746c509342e9881fb2d7644d71c1",
            "dfae5588591b4cd0993d3324ad5d1c8d",
            "5fb35ed19a634443810db6013a595bf9",
            "80536fcb301343ad8c43a05a68c58120",
            "a73b08b27a5740eb9320a4a467446088",
            "7554d113a0f54da3b649252fd8969df3",
            "895b16272a4f4c32a1f572d73eaec700",
            "947011ec13c7404390295e9e2ee39caf",
            "83db5fd4d6db4caa885164519ef833cc",
            "43b31066b58a40f18fd97596b38aef76"
          ]
        },
        "outputId": "f0964c84-91dc-4937-eaae-33ef4a4f7695"
      },
      "source": [
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c019229186e4a99b51ab9bbe4c5b784",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fb35ed19a634443810db6013a595bf9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9096718.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYftDnmguJMr"
      },
      "source": [
        "#align labels with tokenization from XLM-R\n",
        "label_list=[\"n\", \"B-T\", \"T\"]\n",
        "label_to_id = {l: i for i, l in enumerate(label_list)}\n",
        "num_labels=len(label_list)\n",
        "\n",
        "def tokenize_and_align_labels(texts, tags):\n",
        "  tokenized_inputs = tokenizer(\n",
        "      texts,\n",
        "      padding=True,\n",
        "      truncation=True,\n",
        "      # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
        "      is_split_into_words=True,\n",
        "  )\n",
        "  labels = []\n",
        "  for i, label in enumerate(tags):\n",
        "      word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "      previous_word_idx = None\n",
        "      label_ids = []\n",
        "      for word_idx in word_ids:\n",
        "          # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "          # ignored in the loss function.\n",
        "          if word_idx is None:\n",
        "              label_ids.append(-100)\n",
        "          # We set the label for the first token of each word.\n",
        "          elif word_idx != previous_word_idx:\n",
        "              label_ids.append(label_to_id[label[word_idx]])\n",
        "          # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "          # the label_all_tokens flag.\n",
        "          else:\n",
        "              label_ids.append(-100)\n",
        "          previous_word_idx = word_idx\n",
        "\n",
        "      labels.append(label_ids)\n",
        "  tokenized_inputs[\"labels\"] = labels\n",
        "  return tokenized_inputs  \n",
        "\n",
        "\n",
        "train_input_and_labels = tokenize_and_align_labels(train_texts, train_tags)\n",
        "\n",
        "val_input_and_labels = tokenize_and_align_labels(val_texts, val_tags)\n",
        "val_input_and_labels_en = tokenize_and_align_labels(val_texts_en, val_tags_en)\n",
        "val_input_and_labels_fr = tokenize_and_align_labels(val_texts_fr, val_tags_fr)\n",
        "val_input_and_labels_nl = tokenize_and_align_labels(val_texts_nl, val_tags_nl)\n",
        "\n",
        "test_input_and_labels = tokenize_and_align_labels(test_texts, test_tags)\n",
        "test_input_and_labels_en = tokenize_and_align_labels(test_texts_en, test_tags_en)\n",
        "test_input_and_labels_fr = tokenize_and_align_labels(test_texts_fr, test_tags_fr)\n",
        "test_input_and_labels_nl = tokenize_and_align_labels(test_texts_nl, test_tags_nl)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lcPXbZ22yWG"
      },
      "source": [
        "# create dataset that can be used for training with the huggingface trainer\n",
        "class OurDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = OurDataset(train_input_and_labels, train_input_and_labels[\"labels\"])\n",
        "\n",
        "val_dataset = OurDataset(val_input_and_labels, val_input_and_labels[\"labels\"])\n",
        "val_dataset_en = OurDataset(val_input_and_labels_en, val_input_and_labels_en[\"labels\"])\n",
        "val_dataset_fr = OurDataset(val_input_and_labels_fr, val_input_and_labels_fr[\"labels\"])\n",
        "val_dataset_nl = OurDataset(val_input_and_labels_nl, val_input_and_labels_nl[\"labels\"])\n",
        "\n",
        "test_dataset = OurDataset(test_input_and_labels, test_input_and_labels[\"labels\"])\n",
        "test_dataset_en = OurDataset(test_input_and_labels_en, test_input_and_labels_en[\"labels\"])\n",
        "test_dataset_fr = OurDataset(test_input_and_labels_fr, test_input_and_labels_fr[\"labels\"])\n",
        "test_dataset_nl = OurDataset(test_input_and_labels_nl, test_input_and_labels_nl[\"labels\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9miQ8_HxKqGB"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE8JxaF5T9Yd"
      },
      "source": [
        "# return the extracted terms given the token level prediction and the original texts\n",
        "\n",
        "def extract_terms(token_predictions, val_texts):\n",
        "  extracted_terms = set()\n",
        "  # go over all predictions\n",
        "  for i in range(len(token_predictions)):\n",
        "    pred = token_predictions[i]\n",
        "    txt  = val_texts[i]\n",
        "    for j in range(len(pred)):\n",
        "      # if right tag build term and add it to the set otherwise just continue\n",
        "      if pred[j]==\"B-T\":\n",
        "        term=txt[j]\n",
        "        for k in range(j+1,len(pred)):\n",
        "          if pred[k]==\"T\": term+=\" \"+txt[k]\n",
        "          else: break\n",
        "        extracted_terms.add(term)\n",
        "  return extracted_terms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FiN4TVUTDXL"
      },
      "source": [
        "#compute the metrics TermEval style for Trainer\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    extracted_terms=extract_terms(true_predictions, val_texts) # ??????\n",
        "    extracted_terms = set([item.lower() for item in extracted_terms])\n",
        "    gold_set=gold_set_for_validation      # ??????\n",
        "\n",
        "    true_pos=extracted_terms.intersection(gold_set)\n",
        "    recall=len(true_pos)/len(gold_set)\n",
        "    precision=len(true_pos)/len(extracted_terms)\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": 2*(precision*recall)/(precision+recall),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcDLjK-i4-Y8"
      },
      "source": [
        "# training arguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=1,              # total # of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=0,                  # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0,                  # strength of weight decay\n",
        "    learning_rate=2e-5,\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    evaluation_strategy= \"no\",#\"steps\", # or use epoch here\n",
        "    eval_steps=100,\n",
        "    #save_total_limit=1,\n",
        "    load_best_model_at_end=True,   #loads the model with the best evaluation score\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJf_Rnyf26el",
        "outputId": "742cd3c9-5bbf-443d-95c8-75ee69d0590e"
      },
      "source": [
        "# initialize model\n",
        "model = XLMRobertaForTokenClassification.from_pretrained(\"xlm-roberta-base\", num_labels=num_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEg8krxu-MY4"
      },
      "source": [
        "# initialize huggingface trainer\n",
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZIimqAK28qS"
      },
      "source": [
        "# train\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_dYhX6t2FsM"
      },
      "source": [
        "# Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Xcy0k_pfwjxi",
        "outputId": "56b40925-bb94-48d9-a1c8-5f89f63fc0ad"
      },
      "source": [
        "#test\n",
        "test_predictions, test_labels, test_metrics = trainer.predict(test_dataset)\n",
        "test_predictions = np.argmax(test_predictions, axis=2)\n",
        "# Remove ignored index (special tokens)\n",
        "true_test_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(test_prediction, test_label) if l != -100]\n",
        "    for test_prediction, test_label in zip(test_predictions, test_labels)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='900' max='499' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [499/499 06:34]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: n seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.6/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: T seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5wz6JzfHk1B",
        "outputId": "97975df3-980e-458b-f9e5-180d8ae6d0e7"
      },
      "source": [
        "# example output\n",
        "i=1\n",
        "print('{:>10}  {:>10}  {:>10}'.format(\"Text\", \"Label\", \"Prediction\"))\n",
        "for j in range(len(true_test_predictions_en[i])):\n",
        "  print('{:>10}  {:>10}  {:>10}'.format(test_texts[i][j], test_tags[i][j], true_test_predictions_en[i][j]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Text       Label  Prediction\n",
            "       The           n           n\n",
            "  analysis           n           n\n",
            "  included           n           n\n",
            "         a           n           n\n",
            "     large           n           n\n",
            "     study           n           n\n",
            "    sample           n           n\n",
            "      with           n           n\n",
            "      more           n           n\n",
            "      than           n           n\n",
            "    60,000           n           n\n",
            "  patients         B-T           n\n",
            "    across           n           n\n",
            "      4372           n           n\n",
            " hospitals         B-T           n\n",
            "         .           n           n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnY89ltMTrm6"
      },
      "source": [
        "def computeTermEvalMetrics(extracted_terms, gold_df):\n",
        "  #make lower case cause gold standard is lower case\n",
        "  extracted_terms = set([item.lower() for item in extracted_terms])\n",
        "  gold_set=set(gold_df)\n",
        "  true_pos=extracted_terms.intersection(gold_set)\n",
        "  recall=len(true_pos)/len(gold_set)\n",
        "  precision=len(true_pos)/len(extracted_terms)\n",
        "\n",
        "  print(\"Intersection\",len(true_pos))\n",
        "  print(\"Gold\",len(gold_set))\n",
        "  print(\"Extracted\",len(extracted_terms))\n",
        "  print(\"Recall:\", recall)\n",
        "  print(\"Precision:\", precision)\n",
        "  print(\"F1:\", 2*(precision*recall)/(precision+recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSAjQkEAMaMq"
      },
      "source": [
        "test_extracted_terms = extract_terms(true_test_predictions, test_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DrVLBYIaMaU"
      },
      "source": [
        "computeTermEvalMetrics(test_extracted_terms, set(df_htfl_terms_en[\"Term\"]).union(set(df_htfl_terms_fr[\"Term\"])).union(set(df_htfl_terms_nl[\"Term\"])))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}